{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD9zM/uSe+37lpBmf3K8T9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brendanpshea/database_sql/blob/main/Database_11_Data_Storytelling_with_Zombies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Telling a Story with Your Data\n",
        "### Brendan Shea, PhD\n",
        "\n",
        "In this chapter, we delve into the heart of data analysis: the art and science of interpreting your data and communicating your findings effectively. Your journey through this course has equipped you with the fundamental skills to gather, organize, and manipulate data. Now, we turn our attention towards the real-world challenge of extracting meaningful insights from our datasets and presenting these insights in a manner that allows others to understand and act upon them.\n",
        "\n",
        "We will begin by exploring how to clean and structure data to facilitate downstream analysis. This often overlooked step is crucial in ensuring the integrity of your analyses and, consequently, the reliability of your findings.\n",
        "\n",
        "Next, we turn to the essential task of visualizing data. We'll delve into various techniques for presenting different types of data, including geographical and temporal data. We will also discuss the development of interactive dashboards, a powerful tool for real-time data monitoring and decision-making.\n",
        "\n",
        "We will then transition into the realm of descriptive and inferential statistics. Descriptive statistics help us summarize and understand the characteristics of our dataset. Inferential statistics, on the other hand, enable us to make predictions and inferences about a population based on a sample.\n",
        "\n",
        "Finally, we will address the all-important task of report writing. Here we will discuss how to structure a report, how to communicate complex information clearly and succinctly, and how to ensure your report is both engaging and informative.\n",
        "\n",
        "Throughout this chapter, we will be mindful of potential biases and confounding factors that could impact our analyses. We will also discuss the importance of data privacy and ethics, particularly when handling sensitive information.\n"
      ],
      "metadata": {
        "id": "vn4WZd9PErO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case Study: Zombies!\n",
        "\n",
        "Now, let's bring these concepts to life with a case study. You are a junior analyst at the Centers for Disease Control and Prevention (CDC). Suddenly, an outbreak of a mysterious illness begins to spread rapidly across the country. The symptoms appear zombie-like, and public fear is rising. Your task is to analyze the data coming in from across the nation, make sense of it, and communicate your findings to various stakeholders. This high-stakes scenario will give you a taste of what data analysts face in real-world crises.\n",
        "\n",
        "As we proceed through this chapter, we will apply the concepts we learn to this unfolding crisis, helping the CDC understand and combat the spread of this terrifying outbreak. Let's get started!"
      ],
      "metadata": {
        "id": "Cjv75toYFEvJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk8MmCew0IDm"
      },
      "outputs": [],
      "source": [
        "# First, we create a database and connect to it\n",
        "!pip install SQLAlchemy==1.3.24 -q # Needed o avoid problems with more recent version in Colab\n",
        "\n",
        "%load_ext sql\n",
        "%sql sqlite:///zombies.db"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix: A Script to Generate a Random Zombie Outbreak\n",
        "You don't need to run this! I just included it here to show how I generated the data set we're working with. Feel free to play with it to see what happens! (Right now, this is *not* a realistic pandemic data set)."
      ],
      "metadata": {
        "id": "jFmJRoMw0IyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CASES = 5000\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from random import choices, randint\n",
        "from datetime import datetime, timedelta\n",
        "import math\n",
        "\n",
        "# List of states to simulate spreading of the outbreak\n",
        "states = ['MN', 'WI', 'IA', 'SD', 'ND', 'NE', 'IL', 'MI', 'IN', 'OH']\n",
        "\n",
        "# Define the severity levels and case status\n",
        "severity_levels = ['Mild', 'Moderate', 'Severe']\n",
        "case_status = ['Infected', 'Recovered', 'Deceased', 'Unknown']\n",
        "\n",
        "# Function to generate case_status based on age and severity\n",
        "def generate_case_status(age, severity):\n",
        "    if severity == 'Mild':\n",
        "        return choices(case_status, weights=[70, 29, 1, 0])[0] if age != -1 else choices(case_status, weights=[0, 0, 0, 100])[0]\n",
        "    elif severity == 'Moderate':\n",
        "        return choices(case_status, weights=[40, 59, 1, 0])[0] if age != -1 else choices(case_status, weights=[0, 0, 0, 100])[0]\n",
        "    else: # 'Severe'\n",
        "        return choices(case_status, weights=[20, 29, 51, 0])[0] if age > 50 else choices(case_status, weights=[40, 59, 1, 0])[0]\n",
        "\n",
        "# Create dataframe\n",
        "data = {'case_id': [], 'report_date': [], 'location': [], 'symptom_severity': [], 'case_status': [], 'age': []}\n",
        "\n",
        "start_date = datetime(2028, 2, 1)\n",
        "end_date = datetime(2028, 8, 1)\n",
        "num_days = (end_date - start_date).days\n",
        "\n",
        "# Exponential growth parameters\n",
        "a = 1  # initial number of cases\n",
        "r = np.log(2) / 30  # rate, set to double every month\n",
        "\n",
        "# Generate t values (one for each case), evenly spaced between 0 and the total number of days\n",
        "t_values = np.linspace(0, num_days, num=NUM_CASES)\n",
        "\n",
        "# Calculate the number of cases for each day, round to nearest integer\n",
        "case_counts = np.rint(a * np.exp(r * t_values)).astype(int)\n",
        "\n",
        "# Generate dates proportionate to the exponential growth of cases\n",
        "dates = [start_date + timedelta(days=int(t)) for t in t_values]\n",
        "\n",
        "for i in range(NUM_CASES):\n",
        "    # Get the date\n",
        "    date = dates[i]\n",
        "\n",
        "    # generate location based on the date (more recent dates have more states)\n",
        "    location = np.random.choice(states[:max(1, (date-start_date).days//(num_days//len(states)))])\n",
        "\n",
        "    # generate age (more older people as per severity)\n",
        "    age = int(np.random.normal(loc=50, scale=20))\n",
        "    if age < 0: age = 0\n",
        "    if np.random.rand() < 0.1:  # 10% chance of age being unknown\n",
        "        age = -1\n",
        "\n",
        "    # generate symptom severity (more severe for older people)\n",
        "    symptom_severity = choices(severity_levels, weights=[70, 20, 10] if age != -1 else [10, 20, 70])[0]\n",
        "\n",
        "    # generate case_status based on symptom_severity and age\n",
        "    case_status_generated = generate_case_status(age, symptom_severity)\n",
        "\n",
        "    # append generated data to the dictionary\n",
        "    data['case_id'].append(i)\n",
        "    data['report_date'].append(date.strftime(\"%Y-%m-%d\"))\n",
        "    data['location'].append(location)\n",
        "    data['symptom_severity'].append(symptom_severity)\n",
        "    data['case_status'].append(case_status_generated)\n",
        "    data['age'].append(age)\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save DataFrame to CSV\n",
        "df.to_csv('zombie_outbreak.csv', index=False)\n"
      ],
      "metadata": {
        "id": "5MNE7TUB2xRA"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}