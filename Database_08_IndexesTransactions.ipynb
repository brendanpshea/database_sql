{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPzjfooaEV3xQkRi0xFS8Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brendanpshea/database_sql/blob/main/Database_08_IndexesTransactions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Database Performance: Index, Query Plans, and Transaction Management\n",
        "In this chapter, we will explore the inner workings of SQLite using a dataset from the fictional Gotham National Bank. Our focus will be on understanding how indexes, transactions, and database monitoring can optimize SQLite database performance and ensure smooth operations. We will cover the fundamentals of indexes, demonstrate their impact on query speed and database size, and discuss best practices for implementing them effectively.\n",
        "\n",
        "Additionally, we will delve into the concept of transactions and the crucial role they play in ensuring data integrity and reliability. We will examine the ACID properties that transactions must adhere to and showcase how to work with transactions in SQLite using commands like BEGIN, COMMIT, and ROLLBACK.\n",
        "\n",
        "Furthermore, we will emphasize the importance of database monitoring, reporting, and logging in maintaining the health and performance of SQLite databases. We will explore various monitoring techniques, discuss the types of logs generated, and highlight the tools and practices used by database administrators like Oracle to keep databases running optimally.\n",
        "\n",
        "Throughout the chapter, we will use practical examples and step-by-step explanations to illustrate how indexes, transactions, and monitoring can be leveraged to build robust and efficient databases. By the end, you should have a solid foundation in these key concepts and be well-equipped to apply them in your own SQLite projects.\n",
        "\n",
        "Learning Outcomes:\n",
        "\n",
        "1.  Understand the purpose and benefits of indexes in SQLite databases\n",
        "2.  Learn how to create indexes and analyze their impact on query performance and database size\n",
        "3.  Recognize situations where creating an index is advantageous and when it may not be necessary\n",
        "4.  Grasp the concept of transactions and their importance in maintaining data integrity and reliability\n",
        "5.  Become familiar with the ACID properties of transactions and their implications for database consistency\n",
        "6.  Learn how to work with transactions in SQLite using BEGIN, COMMIT, ROLLBACK, and SAVEPOINT commands\n",
        "7.  Understand the challenges of concurrent transactions and the role of locking mechanisms in managing simultaneous access to data\n",
        "8.  Appreciate the significance of database monitoring, reporting, and logging in ensuring optimal performance and health of SQLite databases\n",
        "9.  Gain insights into the tools and techniques used by database administrators to monitor and manage databases effectively\n",
        "\n",
        "Keywords: SQLite, indexes, transactions, database monitoring, reporting, logging, query performance, database size, ACID properties, data integrity, reliability, concurrency, locking\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P8p0DiGl7a6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gotham National Bank Database\n",
        "In this chapter, we'll be exploring the inner workings of **SQLite** using a dataset from the fictional **Gotham National Bank**. Our database, *gotham.db*, contains two tables:\n",
        "\n",
        "1.  **Customers**: Stores customer information like name, address, and contact details.\n",
        "2.  **Accounts**: Holds account-related data such as account type, balance, and creation date, with a foreign key linking to the Customers table.\n",
        "\n",
        "Throughout this chapter, we'll use these tables to understand how **indexes** and **transactions** can optimize our SQLite database performance. We'll cover the fundamentals of indexes, demonstrate their impact on query speed and database size, and discuss best practices for implementing them effectively."
      ],
      "metadata": {
        "id": "OlZDsIe35EiY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qsF2EjFB6Dyf"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/brendanpshea/database_sql/raw/main/data/gotham.db -q -nc\n",
        "%load_ext sql\n",
        "%sql sqlite:///gotham.db\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rc5uIXlz5Nnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Database Schema for Gotham City Bank\n",
        "Here is the database schema."
      ],
      "metadata": {
        "id": "Fy6vnP-_8Nub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "-- we are going to turn on \"profiling\" this lesson\n",
        "PRAGMA profile = 1;\n",
        "-- get table schema using sqlite master\n",
        "SELECT sql FROM sqlite_master WHERE type='table';"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "kx50EYAW6ao7",
        "outputId": "02b993de-a0f4-4d58-aed2-f7aaf104bacb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///gotham.db\n",
            "Done.\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('CREATE TABLE Customers (\\n    CustomerID INTEGER PRIMARY KEY AUTOINCREMENT,\\n    FirstName VARCHAR(50) NOT NULL,\\n    LastName VARCHAR(50) NOT NULL,\\ ... (35 characters truncated) ... dress VARCHAR(255),\\n    City VARCHAR(50),\\n    State VARCHAR(50),\\n    ZipCode VARCHAR(10),\\n    PhoneNumber VARCHAR(15),\\n    Email VARCHAR(100)\\n)',),\n",
              " ('CREATE TABLE sqlite_sequence(name,seq)',),\n",
              " ('CREATE TABLE Accounts (\\n    AccountID INTEGER PRIMARY KEY AUTOINCREMENT,\\n    CustomerID INT,\\n    AccountType VARCHAR(20),\\n    Balance DECIMAL(15, 2) DEFAULT 0.00,\\n    CreatedDate DATE,\\n    FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)\\n)',)]"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>sql</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>CREATE TABLE Customers (<br>    CustomerID INTEGER PRIMARY KEY AUTOINCREMENT,<br>    FirstName VARCHAR(50) NOT NULL,<br>    LastName VARCHAR(50) NOT NULL,<br>    MiddleInitial CHAR(1),<br>    Address VARCHAR(255),<br>    City VARCHAR(50),<br>    State VARCHAR(50),<br>    ZipCode VARCHAR(10),<br>    PhoneNumber VARCHAR(15),<br>    Email VARCHAR(100)<br>)</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>CREATE TABLE sqlite_sequence(name,seq)</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>CREATE TABLE Accounts (<br>    AccountID INTEGER PRIMARY KEY AUTOINCREMENT,<br>    CustomerID INT,<br>    AccountType VARCHAR(20),<br>    Balance DECIMAL(15, 2) DEFAULT 0.00,<br>    CreatedDate DATE,<br>    FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)<br>)</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Closer Look at Customers and Accounts\n",
        "Now, let's take a quick look at the head of our table."
      ],
      "metadata": {
        "id": "ps0Bhu1F7sUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT * FROM Customers LIMIT 5;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "u4_M74pe8dsr",
        "outputId": "f3cd8f99-3b14-40e0-bcb2-76e61607c922"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///gotham.db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 'Bruce', 'Wayne', None, '1007 Mountain Drive', 'Gotham', 'NY', '10001', '123-456-7890', 'bruce.wayne@gothambank.com'),\n",
              " (2, 'Selina', 'Kyle', None, '123 Cat St', 'Bl√ºdhaven', 'NY', '20002', '234-567-8901', 'selina.kyle@gothambank.com'),\n",
              " (3, 'James', 'Gordon', None, '789 Police Plaza', 'Gotham', 'NY', '10003', '345-678-9012', 'james.gordon@gothambank.com'),\n",
              " (4, 'Harvey', 'Dent', None, '456 Lawyer Ave', 'Metropolis', 'NY', '30004', '456-789-0123', 'harvey.dent@gothambank.com'),\n",
              " (5, 'Pamela', 'Isley', None, '369 Botanic St', 'Gotham', 'NY', '10005', '567-890-1234', 'pamela.isley@gothambank.com')]"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>CustomerID</th>\n",
              "            <th>FirstName</th>\n",
              "            <th>LastName</th>\n",
              "            <th>MiddleInitial</th>\n",
              "            <th>Address</th>\n",
              "            <th>City</th>\n",
              "            <th>State</th>\n",
              "            <th>ZipCode</th>\n",
              "            <th>PhoneNumber</th>\n",
              "            <th>Email</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>1</td>\n",
              "            <td>Bruce</td>\n",
              "            <td>Wayne</td>\n",
              "            <td>None</td>\n",
              "            <td>1007 Mountain Drive</td>\n",
              "            <td>Gotham</td>\n",
              "            <td>NY</td>\n",
              "            <td>10001</td>\n",
              "            <td>123-456-7890</td>\n",
              "            <td>bruce.wayne@gothambank.com</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2</td>\n",
              "            <td>Selina</td>\n",
              "            <td>Kyle</td>\n",
              "            <td>None</td>\n",
              "            <td>123 Cat St</td>\n",
              "            <td>Bl√ºdhaven</td>\n",
              "            <td>NY</td>\n",
              "            <td>20002</td>\n",
              "            <td>234-567-8901</td>\n",
              "            <td>selina.kyle@gothambank.com</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>3</td>\n",
              "            <td>James</td>\n",
              "            <td>Gordon</td>\n",
              "            <td>None</td>\n",
              "            <td>789 Police Plaza</td>\n",
              "            <td>Gotham</td>\n",
              "            <td>NY</td>\n",
              "            <td>10003</td>\n",
              "            <td>345-678-9012</td>\n",
              "            <td>james.gordon@gothambank.com</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>4</td>\n",
              "            <td>Harvey</td>\n",
              "            <td>Dent</td>\n",
              "            <td>None</td>\n",
              "            <td>456 Lawyer Ave</td>\n",
              "            <td>Metropolis</td>\n",
              "            <td>NY</td>\n",
              "            <td>30004</td>\n",
              "            <td>456-789-0123</td>\n",
              "            <td>harvey.dent@gothambank.com</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>5</td>\n",
              "            <td>Pamela</td>\n",
              "            <td>Isley</td>\n",
              "            <td>None</td>\n",
              "            <td>369 Botanic St</td>\n",
              "            <td>Gotham</td>\n",
              "            <td>NY</td>\n",
              "            <td>10005</td>\n",
              "            <td>567-890-1234</td>\n",
              "            <td>pamela.isley@gothambank.com</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT * FROM Accounts LIMIT 5;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "Ol8O-SD-8fuB",
        "outputId": "1c965d9e-c78c-4490-d509-1574d16a449c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///gotham.db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1, 'Checking', 15000, '2021-01-10'),\n",
              " (2, 1, 'Savings', 75000, '2021-02-11'),\n",
              " (3, 2, 'Checking', 32000, '2022-03-05'),\n",
              " (4, 3, 'Checking', 86000, '2023-04-15'),\n",
              " (5, 4, 'Checking', 22000, '2024-05-20')]"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>AccountID</th>\n",
              "            <th>CustomerID</th>\n",
              "            <th>AccountType</th>\n",
              "            <th>Balance</th>\n",
              "            <th>CreatedDate</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>1</td>\n",
              "            <td>1</td>\n",
              "            <td>Checking</td>\n",
              "            <td>15000</td>\n",
              "            <td>2021-01-10</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2</td>\n",
              "            <td>1</td>\n",
              "            <td>Savings</td>\n",
              "            <td>75000</td>\n",
              "            <td>2021-02-11</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>3</td>\n",
              "            <td>2</td>\n",
              "            <td>Checking</td>\n",
              "            <td>32000</td>\n",
              "            <td>2022-03-05</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>4</td>\n",
              "            <td>3</td>\n",
              "            <td>Checking</td>\n",
              "            <td>86000</td>\n",
              "            <td>2023-04-15</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>5</td>\n",
              "            <td>4</td>\n",
              "            <td>Checking</td>\n",
              "            <td>22000</td>\n",
              "            <td>2024-05-20</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What are Indexes and How Do I Create Them?\n",
        "\n",
        "If you've ever used a book index to quickly locate a specific topic, you already understand the basic concept of a database **index**. In the context of databases, an index is a separate data structure that allows the database engine to find and retrieve data more efficiently without having to scan the entire table.\n",
        "\n",
        "When you create a table, SQLite (like all versions of SQL) automatically creates a unique index on the **primary key** column(s). However, you can also create additional indexes on other columns to speed up frequently used queries.\n",
        "\n",
        "To create an index in SQL, you use the **CREATE INDEX** statement with the following syntax:\n",
        "\n",
        "```sql\n",
        "CREATE [UNIQUE] INDEX index_name\n",
        "ON table_name (column1 [, column2, ...]);\n",
        "```\n",
        "\n",
        "Here's a breakdown of the components:\n",
        "\n",
        "-   `UNIQUE`: Optional keyword that creates a unique index, ensuring no duplicate values in the indexed column(s).\n",
        "-   `index_name`: The name you want to give your index.\n",
        "-   `table_name`: The name of the table on which you're creating the index.\n",
        "-   `column1, column2, ...`: The column(s) to be indexed. You can index multiple columns by separating them with commas.\n",
        "\n",
        "For example, let's say we want to create an index on the *LastName* column of our *Customers* table:!"
      ],
      "metadata": {
        "id": "cwWgv-hn7Ihb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "DROP INDEX IF EXISTS idx_customers_lastname;\n",
        "CREATE INDEX idx_customers_lastname\n",
        "ON Customers (LastName);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWB_i0vg89Vo",
        "outputId": "5fc5b99f-35e4-4e6b-b831-301d41322eac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///gotham.db\n",
            "Done.\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This statement creates an index named idx_customer_lastname on the LastName column, allowing for faster searches based on customer last names. This will allow us to search customers by their last name more quickly.\n",
        "\n",
        "SQLite supports several types of indexes, including unique indexes, which ensure that the indexed column(s) contain no duplicate values, and partial indexes, which only index a subset of rows based on a specified condition.\n",
        "\n",
        "Creating appropriate indexes is crucial for optimizing database performance, but how do they actually impact query speed? In the next section, we'll explore the power of indexes in action using the EXPLAIN QUERY PLAN command and some practical examples from our Gotham City dataset."
      ],
      "metadata": {
        "id": "z0rumVik9GtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How Indexes Impact Speed\n",
        "\n",
        "To understand the impact of indexes on query speed, we'll use the **EXPLAIN QUERY PLAN** command. This command provides insight into how SQLite executes a query, including which indexes (if any) are being used.\n",
        "\n",
        "Let's start with an example query on our *Accounts* table that gets customers with higher than average balances"
      ],
      "metadata": {
        "id": "bVpTi1eC9UKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT * FROM Accounts\n",
        "WHERE Balance > (SELECT AVG(Balance) FROM Accounts)\n",
        "ORDER BY Balance DESC\n",
        "LIMIT 5;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "kFFBXZs3C5i5",
        "outputId": "6ccc2ae4-e460-46dd-a136-c1edb82bfa1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///gotham.db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(8136, 7952, 'Savings', 92802.15340000001, '2003-01-18'),\n",
              " (3401, 4699, 'Savings', 91534.3495, '2015-03-25'),\n",
              " (304, 277, 'Savings', 91283.00280000002, '2021-05-08'),\n",
              " (10, 8, 'Checking', 91000, '2024-10-10'),\n",
              " (5953, 5751, 'Savings', 90689.35260000001, '2013-12-29')]"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>AccountID</th>\n",
              "            <th>CustomerID</th>\n",
              "            <th>AccountType</th>\n",
              "            <th>Balance</th>\n",
              "            <th>CreatedDate</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>8136</td>\n",
              "            <td>7952</td>\n",
              "            <td>Savings</td>\n",
              "            <td>92802.15340000001</td>\n",
              "            <td>2003-01-18</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>3401</td>\n",
              "            <td>4699</td>\n",
              "            <td>Savings</td>\n",
              "            <td>91534.3495</td>\n",
              "            <td>2015-03-25</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>304</td>\n",
              "            <td>277</td>\n",
              "            <td>Savings</td>\n",
              "            <td>91283.00280000002</td>\n",
              "            <td>2021-05-08</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>10</td>\n",
              "            <td>8</td>\n",
              "            <td>Checking</td>\n",
              "            <td>91000</td>\n",
              "            <td>2024-10-10</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>5953</td>\n",
              "            <td>5751</td>\n",
              "            <td>Savings</td>\n",
              "            <td>90689.35260000001</td>\n",
              "            <td>2013-12-29</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's see what the \"query plan\" is for this:"
      ],
      "metadata": {
        "id": "VdGfHJDTDfCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "DROP INDEX IF EXISTS idx_accounts_balance;\n",
        "\n",
        "EXPLAIN QUERY PLAN\n",
        "SELECT * FROM Accounts\n",
        "WHERE Balance > (SELECT AVG(Balance) FROM Accounts)\n",
        "ORDER BY Balance DESC;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Bdi_nxgZ9lwk",
        "outputId": "811eaafa-343d-4c9b-9bf0-12d7ad4c562d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///gotham.db\n",
            "Done.\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3, 0, 0, 'SCAN Accounts'),\n",
              " (8, 0, 0, 'SCALAR SUBQUERY 1'),\n",
              " (13, 8, 0, 'SCAN Accounts'),\n",
              " (31, 0, 0, 'USE TEMP B-TREE FOR ORDER BY')]"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>id</th>\n",
              "            <th>parent</th>\n",
              "            <th>notused</th>\n",
              "            <th>detail</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>3</td>\n",
              "            <td>0</td>\n",
              "            <td>0</td>\n",
              "            <td>SCAN Accounts</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>8</td>\n",
              "            <td>0</td>\n",
              "            <td>0</td>\n",
              "            <td>SCALAR SUBQUERY 1</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>13</td>\n",
              "            <td>8</td>\n",
              "            <td>0</td>\n",
              "            <td>SCAN Accounts</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>31</td>\n",
              "            <td>0</td>\n",
              "            <td>0</td>\n",
              "            <td>USE TEMP B-TREE FOR ORDER BY</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you look at the query plan here, you'll notice a few key terms that pop out:\n",
        "\n",
        "-   **Full Table Scan**: A full table scan occurs when SQLite reads every row in a table to find the data that matches the query conditions. In this case, `SCAN Accounts` indicates that SQLite is performing a full table scan on the *Accounts* table. Full table scans can be inefficient, especially for large tables, as they require reading and checking every single row. This will change when we create an index.\n",
        "-   **Scalar Subquery**: A scalar subquery is a subquery that returns a single value. In this example, `SCALAR SUBQUERY 1` refers to the subquery `(SELECT AVG(Balance) FROM Accounts)`, which calculates the average balance of all accounts. The result of this subquery is used in the main query's WHERE clause.\n",
        "-   **Temporary B-Tree**: In this case, `USE TEMP B-TREE FOR ORDER BY` indicates that SQLite is using a temporary B-tree data structure to sort the result set in descending order by the *Balance* column. We'll dive deeper into B-trees in a future section."
      ],
      "metadata": {
        "id": "BHy58HwN-TYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Impact of Indexes\n",
        "\n",
        "If an index were created on the `Balance` column, the query execution plan would likely be different. For example, with an index on `Balance`, the execution plan might show an **index search** instead of a full table scan, resulting in faster query execution times.\n",
        "\n",
        "To create an index on the `Balance` column, you could use the following command:"
      ],
      "metadata": {
        "id": "vKvSgWmD-hSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "CREATE INDEX idx_accounts_balance\n",
        "ON Accounts (Balance);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8bqlxQa-gsh",
        "outputId": "83ec3701-dedc-4293-e924-238dbac4cdbe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///gotham.db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's see what happens to our query plan:"
      ],
      "metadata": {
        "id": "k1IidaNe-l7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "EXPLAIN QUERY PLAN\n",
        "SELECT * FROM Accounts\n",
        "WHERE Balance > (SELECT AVG(Balance) FROM Accounts)\n",
        "ORDER BY Balance DESC;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "dQq1f2P8-lJm",
        "outputId": "82b2e581-5fe0-44e2-8d4d-f432bfb2862b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///gotham.db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(4, 0, 0, 'SEARCH Accounts USING INDEX idx_accounts_balance (Balance>?)'),\n",
              " (8, 0, 0, 'SCALAR SUBQUERY 1'),\n",
              " (13, 8, 0, 'SCAN Accounts USING COVERING INDEX idx_accounts_balance')]"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>id</th>\n",
              "            <th>parent</th>\n",
              "            <th>notused</th>\n",
              "            <th>detail</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>4</td>\n",
              "            <td>0</td>\n",
              "            <td>0</td>\n",
              "            <td>SEARCH Accounts USING INDEX idx_accounts_balance (Balance&gt;?)</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>8</td>\n",
              "            <td>0</td>\n",
              "            <td>0</td>\n",
              "            <td>SCALAR SUBQUERY 1</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>13</td>\n",
              "            <td>8</td>\n",
              "            <td>0</td>\n",
              "            <td>SCAN Accounts USING COVERING INDEX idx_accounts_balance</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SQLite now uses the idx_account_balance index to search for matching rows, resulting in a more efficient query execution. Instead of scanning the entire table, it can quickly locate the relevant rows using the index.\n",
        "\n",
        "Some new terms you'll notice:\n",
        "\n",
        "1.  **Index Scan**: An index scan is a type of table access that uses an index to locate the required data. In this example, `SEARCH Accounts USING INDEX idx_accounts_balance (Balance>?)` means that SQLite is using the *idx_accounts_balance* index to find rows where the *Balance* is greater than the result of the scalar subquery.\n",
        "2.  **Covering Index**: A covering index is an index that contains all the columns required to satisfy a query, eliminating the need for additional table lookups. In the updated plan, `SCAN Accounts USING COVERING INDEX idx_accounts_balance` indicates that the *idx_accounts_balance* index is a covering index for the subquery. This means that all the data needed to calculate the average balance is available within the index itself, making the query more efficient.\n"
      ],
      "metadata": {
        "id": "yZnmhKLV-1Nq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Timing Our Queries\n",
        "To further demonstrate the performance impact, let's measure the execution time of our query with and without the index. We'll be using Colab's builtin **timeit** function, which will run this query many times, and give us the average runninng time. This helps miminize the role of chance in evaluating query performance based on a single case."
      ],
      "metadata": {
        "id": "1lHtyz8eIAoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "-- to start, drop the index\n",
        "DROP INDEX idx_accounts_balance;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZu5-Ev0-9i_",
        "outputId": "9158ceb8-fb57-4e18-dedb-3154c98cf3bb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///gotham.db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 1\n",
        "%%sql\n",
        "-- This will run this query many times\n",
        "SELECT * FROM Accounts\n",
        "WHERE Balance > (SELECT AVG(Balance) FROM Accounts)\n",
        "ORDER BY Balance DESC;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cj6twxX_Hfb",
        "outputId": "901d68a8-3418-4ced-9f1f-01d218a772bd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///gotham.db\n",
            "Done.\n",
            " * sqlite:///gotham.db\n",
            "Done.\n",
            " * sqlite:///gotham.db\n",
            "Done.\n",
            " * sqlite:///gotham.db\n",
            "Done.\n",
            " * sqlite:///gotham.db\n",
            "Done.\n",
            " * sqlite:///gotham.db\n",
            "Done.\n",
            " * sqlite:///gotham.db\n",
            "Done.\n",
            "34.9 ms ¬± 3.3 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "-- Recreate our index\n",
        "CREATE INDEX idx_accounts_balance\n",
        "ON Accounts (Balance);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY7mkE6O_rlc",
        "outputId": "538565fb-c779-4e32-a526-49ea5f700d77"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///gotham.db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 1\n",
        "%%sql\n",
        "-- Now run the query with the index\n",
        "SELECT * FROM Accounts\n",
        "WHERE Balance > 25000 AND  Balance < 50000;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBa4gnRA_31L",
        "outputId": "2c04a65a-2a92-4cc8-e5fe-251ac2a2d0cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///gotham.db\n",
            "Done.\n",
            " * sqlite:///gotham.db\n",
            "Done.\n",
            " * sqlite:///gotham.db\n",
            "Done.\n",
            " * sqlite:///gotham.db\n",
            "Done.\n",
            " * sqlite:///gotham.db\n",
            "Done.\n",
            " * sqlite:///gotham.db\n",
            "Done.\n",
            " * sqlite:///gotham.db\n",
            "Done.\n",
            "24.9 ms ¬± 4.74 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the specific results you get will vary each time you run the test, you should find that (on average) the index scan runs a bit faster than the full table scan."
      ],
      "metadata": {
        "id": "HGWbpHNzIfpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How Indexes Impact Storage\n",
        "Now that we've seen how indexes can significantly improve query performance, let's explore how they impact database storage. To understand this, we first need to discuss how SQLite (and many other databases) store data using a data structure called a B-tree.\n",
        "\n",
        "### B-trees: The Backbone of Database Storage\n",
        "\n",
        "A B-tree is a self-balancing tree data structure that maintains sorted data and allows for efficient insertion, deletion, and search operations. B-trees are particularly well-suited for databases because they optimize disk I/O operations, which is crucial when dealing with large amounts of data that cannot fit entirely in memory.\n",
        "\n",
        "In a B-tree, each node contains multiple keys and pointers to child nodes. The keys within a node are kept in sorted order, and each key is associated with two pointers:\n",
        "\n",
        "1.  A pointer to the child node containing keys less than the current key.\n",
        "2.  A pointer to the child node containing keys greater than or equal to the current key.\n",
        "\n",
        "This structure allows for quick traversal and search operations, as the database can navigate the tree by comparing the desired key with the keys in each node and following the appropriate pointers.\n",
        "\n",
        "### How SQLite Uses B-trees\n",
        "\n",
        "SQLite uses B-trees to store both tables and indexes. When you create a table, SQLite creates a B-tree where each node contains one or more rows of data. The rows within a node are sorted by the primary key, enabling efficient lookups and range queries.\n",
        "\n",
        "For example, let's consider a simplified representation of the *Accounts* table:\n",
        "\n",
        "```\n",
        "AccountID | CustomerID | Balance\n",
        "1         | 1          | 10000\n",
        "2         | 1          | 5000\n",
        "3         | 2          | 7500\n",
        "4         | 3          | 12000`\n",
        "```\n",
        "\n",
        "In the table's B-tree, the rows would be stored in nodes, sorted by the primary key (AccountID):\n",
        "\n",
        "```\n",
        "Node 1: (1, 1, 10000) | (2, 1, 5000)\n",
        "Node 2: (3, 2, 7500)  | (4, 3, 12000)\n",
        "```\n",
        "\n",
        "When you create an index on a column, SQLite generates a separate B-tree specifically for that index. The index B-tree stores the indexed column's values along with pointers to the corresponding rows in the table's B-tree.\n",
        "\n",
        "Let's say we create an index on the *Balance* column. Then the *idx_accounts_balance* index B-tree would store the *Balance* values in sorted order, along with pointers to the corresponding rows in the *Accounts* table's B-tree:\n",
        "\n",
        "```sql\n",
        "Node 1: (5000, pointer to row 2) | (7500, pointer to row 3)\n",
        "Node 2: (10000, pointer to row 1) | (12000, pointer to row 4)\n",
        "```\n",
        "\n",
        "When you query the table using the indexed column, SQLite can quickly traverse the index B-tree to find the matching values and then follow the pointers to retrieve the full row data from the table's B-tree.\n",
        "\n",
        "By using B-trees for both tables and indexes, SQLite ensures efficient data storage and retrieval, even for large datasets. However, it's important to keep in mind that creating indexes also requires additional storage space, as each index maintains its own B-tree structure.\n"
      ],
      "metadata": {
        "id": "2x6r4wNZJ2Hz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graphic: B-Trees\n",
        "Here's what our B-tree for our original table might look like:\n"
      ],
      "metadata": {
        "id": "xEt2fbfSLkvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from IPython.display import Image, display, HTML\n",
        "\n",
        "def mm(graph):\n",
        "    graphbytes = graph.encode(\"utf8\")\n",
        "    base64_bytes = base64.b64encode(graphbytes)\n",
        "    base64_string = base64_bytes.decode(\"ascii\")\n",
        "    display(Image(url=\"https://mermaid.ink/img/\" + base64_string))\n",
        "\n",
        "\n",
        "mm(\"\"\"\n",
        "graph TB\n",
        "  subgraph Accounts Table B-tree - sorting by id\n",
        "    N1((Node 1)) --- |pointer to next/previous node| N2((Node 2))\n",
        "    N1 --- |contains| A1[AccountID - key: 1<br>CustomerID: 1<br>Balance: 10000]\n",
        "    N1 --- |contains| A2[AccountID - key: 2<br>CustomerID: 1<br>Balance: 5000]\n",
        "    N2 --- |contains| A3[AccountID - key: 3<br>CustomerID: 2<br>Balance: 7500]\n",
        "    N2 --- |contains| A4[AccountID - key: 4<br>CustomerID: 3<br>Balance: 12000]\n",
        "  end\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "2qECvrr-IpTc",
        "outputId": "5424f388-2397-4660-aa4e-61e0ee58219a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://mermaid.ink/img/CmdyYXBoIFRCCiAgc3ViZ3JhcGggQWNjb3VudHMgVGFibGUgQi10cmVlIC0gc29ydGluZyBieSBpZAogICAgTjEoKE5vZGUgMSkpIC0tLSB8cG9pbnRlciB0byBuZXh0L3ByZXZpb3VzIG5vZGV8IE4yKChOb2RlIDIpKQogICAgTjEgLS0tIHxjb250YWluc3wgQTFbQWNjb3VudElEIC0ga2V5OiAxPGJyPkN1c3RvbWVySUQ6IDE8YnI+QmFsYW5jZTogMTAwMDBdCiAgICBOMSAtLS0gfGNvbnRhaW5zfCBBMltBY2NvdW50SUQgLSBrZXk6IDI8YnI+Q3VzdG9tZXJJRDogMTxicj5CYWxhbmNlOiA1MDAwXQogICAgTjIgLS0tIHxjb250YWluc3wgQTNbQWNjb3VudElEIC0ga2V5OiAzPGJyPkN1c3RvbWVySUQ6IDI8YnI+QmFsYW5jZTogNzUwMF0KICAgIE4yIC0tLSB8Y29udGFpbnN8IEE0W0FjY291bnRJRCAtIGtleTogNDxicj5DdXN0b21lcklEOiAzPGJyPkJhbGFuY2U6IDEyMDAwXQogIGVuZAo=\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And here's what the B-tree for the index might look like:"
      ],
      "metadata": {
        "id": "mCnKWYRjPhM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mm(\"\"\"\n",
        "graph TB\n",
        "  subgraph Balance Index B-tree - sorting by balance\n",
        "    IN1((Node 1)) --- | points to next/previous node | IN2((Node 2))\n",
        "    IN1 --- |contains| IA2[Balance - key: 5000<br>Pointer to Account 2]\n",
        "    IN1 --- |contains| IA3[Balance - key: 7500<br>Pointer to Account 3]\n",
        "    IN2 --- |contains| IA1[Balance - key: 10000<br>Pointer to Account 1]\n",
        "    IN2 --- |contains| IA4[Balance - key: 12000<br>Pointer to Account 4]\n",
        "  end\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "djEJaH77NyuS",
        "outputId": "74826456-ff7e-4b94-808e-4c195f7ec843"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://mermaid.ink/img/CmdyYXBoIFRCCiAgc3ViZ3JhcGggQmFsYW5jZSBJbmRleCBCLXRyZWUgLSBzb3J0aW5nIGJ5IGJhbGFuY2UKICAgIElOMSgoTm9kZSAxKSkgLS0tIHwgcG9pbnRzIHRvIG5leHQvcHJldmlvdXMgbm9kZSB8IElOMigoTm9kZSAyKSkKICAgIElOMSAtLS0gfGNvbnRhaW5zfCBJQTJbQmFsYW5jZSAtIGtleTogNTAwMDxicj5Qb2ludGVyIHRvIEFjY291bnQgMl0KICAgIElOMSAtLS0gfGNvbnRhaW5zfCBJQTNbQmFsYW5jZSAtIGtleTogNzUwMDxicj5Qb2ludGVyIHRvIEFjY291bnQgM10KICAgIElOMiAtLS0gfGNvbnRhaW5zfCBJQTFbQmFsYW5jZSAtIGtleTogMTAwMDA8YnI+UG9pbnRlciB0byBBY2NvdW50IDFdCiAgICBJTjIgLS0tIHxjb250YWluc3wgSUE0W0JhbGFuY2UgLSBrZXk6IDEyMDAwPGJyPlBvaW50ZXIgdG8gQWNjb3VudCA0XQogIGVuZAo=\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking File Size\n",
        "Because indexes require the construction of new B-trees, they require additional disk space. We can  check the file size (using Windows, Linux, etc.). Let's first first check the size our database:"
      ],
      "metadata": {
        "id": "Yu3uUArmpe4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In ubuntu du gives file size\n",
        "!du -h gotham.db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoqlNmixNzqX",
        "outputId": "bb7cdfc8-02c5-41cf-fdb4-111ddf82915a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9M\tgotham.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's see what happens when we an index."
      ],
      "metadata": {
        "id": "a0PTDDWiqHLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "DROP INDEX IF EXISTS idx_accounts_balance;\n",
        "-- create an index based on first name, last name, phone\n",
        "CREATE INDEX idx_customers_first_last_phone\n",
        "ON Customers (FirstName, LastName, PhoneNumber);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0v_6dzrqLus",
        "outputId": "69417c43-4498-4031-8e47-a88cf9cc77d2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * sqlite:///gotham.db\n",
            "Done.\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we can check the size again\n",
        "!du -h gotham.db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BADn2cB2rQdH",
        "outputId": "08d15d9e-c7db-4d9d-be5d-c699d750edea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0M\tgotham.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While your results migth vary somewhat, here's what I got from running these commands:\n",
        "\n",
        "- The database size before building the index was 1.9 mb\n",
        "- The database size after building the index was 2.2 mb.\n",
        "\n",
        "This is a large difference--over 10%--and reinforces the principle that indexes (especially ones that combine multiple columns) need to be used with care."
      ],
      "metadata": {
        "id": "FAeu39hJre4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Oracle's Guide to Creating Indexes\n",
        "\n",
        "Hello, aspiring database heroes! I'm Oracle (formerly \"Batgirl\"), your trusty guide through the complex world of SQLite indexing. As the all-seeing database sage of Gotham City, I'm here to share some wisdom on when and how to create indexes for your tables.\n",
        "\n",
        "First, let's set the scene. Imagine you're working for the Gotham City Police Department (GCPD), and you've been tasked with optimizing their criminal database. The database contains tables like *Suspects*, *Crimes*, and *Investigations*, each with thousands of rows. Your job is to ensure that queries run faster than the Batmobile on a pursuit.\n",
        "\n",
        "### When to Create an Index\n",
        "\n",
        "1.  *Frequently Used Columns*. If you find yourself constantly querying the database to find suspects by their last name, it's a good idea to create an index on the *LastName* column of the *Suspects* table. This way, when Commissioner Gordon asks for information on \"Napier,\" the database can quickly locate the relevant records without having to scan the entire table.\n",
        "2.  *JOIN Columns*. When you're joining tables based on a foreign key, such as joining the *Crimes* and *Investigations* tables on the *CrimeID* column, creating an index on the foreign key column can significantly speed up the JOIN operation. This is particularly important when dealing with large tables, as it helps avoid full table scans.\n",
        "3.  *Columns Used in ORDER BY or GROUP BY*. If you frequently sort the results of your queries, like displaying the list of crimes ordered by the date they occurred, consider creating an index on the column used in the ORDER BY clause. The same goes for columns used in GROUP BY clauses. Indexes help optimize these operations by allowing SQLite to quickly sort or group the data without having to perform a full table scan.\n",
        "\n",
        "### When Not to Create an Index\n",
        "\n",
        "1.  *Small Tables*. If your table is small, like a list of Gotham's most notorious villains (which hopefully doesn't grow too large), creating an index might not provide significant performance benefits. The overhead of maintaining the index could outweigh the time saved during queries.\n",
        "2.  *Columns with Low Cardinality*. Cardinality refers to the number of unique values in a column. If a column has low cardinality, such as a *VillainStatus* column with only a few possible values (\"At Large,\" \"In Custody,\" \"Reformed\"), creating an index on that column might not be effective. SQLite would still need to scan a large portion of the index to find the desired values.\n",
        "3.  *Frequently Updated Columns*. If a column is frequently updated, like the *CurrentLocation* of a suspect, creating an index on that column could slow down the update operations. Each time the column is updated, SQLite needs to update both the table and the index B-tree, causing additional overhead.\n",
        "\n",
        "### Analyzing Query Plans and Execution Speed\n",
        "\n",
        "Before creating an index, it's essential to analyze the current query plans and execution speeds. Use the `EXPLAIN QUERY PLAN` command to see how SQLite is executing your queries. If you notice full table scans or suboptimal execution plans, consider creating an index on the columns involved.\n",
        "\n",
        "For example, let's say you have a query that searches for crimes committed by a specific suspect:\n",
        "\n",
        "```sql\n",
        "EXPLAIN QUERY PLAN\n",
        "SELECT * FROM Crimes\n",
        "WHERE SuspectID = (SELECT SuspectID FROM Suspects WHERE LastName = 'Joker');\n",
        "```\n",
        "\n",
        "If the query plan shows a full table scan on the *Suspects* table, creating an index on the *LastName* column could improve the query's performance.\n",
        "\n",
        "Remember, indexes are like Robin to your Batman - they're there to help you fight crime (or in this case, slow queries). But just like how Batman doesn't bring Robin to every mission, you don't need an index on every column. Use them wisely, and your database will be the hero Gotham deserves!"
      ],
      "metadata": {
        "id": "wuioIVmztSae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Transactions and ACID Properties\n",
        "\n",
        "When working with databases, ensuring data integrity and reliability is crucial. This is where transactions come into play. A **transaction** is a sequence of database operations that are treated as a single unit of work. Transactions are designed to maintain the consistency and integrity of the database, even in the face of failures or concurrent access by multiple users.\n",
        "\n",
        "To better understand transactions, let's consider an example from our Gotham City bank database. Imagine that Bruce Wayne wants to transfer $10,000 from his savings account to his checking account. This transaction would involve two steps:\n",
        "\n",
        "1.  Deducting \\$10,000 from Bruce's savings account.\n",
        "2.  Adding \\$10,000 to Bruce's checking account.\n",
        "\n",
        "If either of these steps fails, the entire transaction should be rolled back to maintain the consistency of the database. We wouldn't want to deduct the money from the savings account without adding it to the checking account, or vice versa.\n",
        "\n",
        "### ACID Properties\n",
        "\n",
        "To ensure the reliability and consistency of transactions, they must adhere to the ACID properties:\n",
        "\n",
        "1.  **Atomicity**. A transaction must be treated as an atomic unit of work, meaning that either all of its operations are completed successfully, or none of them are. If any part of the transaction fails, the entire transaction is rolled back, and the database is left unchanged. In our example, if the deduction from the savings account succeeds, but the addition to the checking account fails, the transaction would be rolled back, and the savings account would be restored to its original balance.\n",
        "2.  **Consistency**. A transaction must take the database from one consistent state to another. This means that the transaction must ensure that all data integrity constraints are satisfied before it completes. For example, if our bank database has a constraint that account balances cannot be negative, any transaction that would result in a negative balance must be rolled back to maintain consistency.\n",
        "3.  **Isolation**. Transactions must be isolated from one another. This means that the intermediate state of a transaction should not be visible to other transactions. Each transaction should execute as if it were the only one running on the database. This isolation helps prevent issues like dirty reads (reading uncommitted data from another transaction) and non-repeatable reads (getting different results from the same query within a single transaction due to changes made by other transactions).\n",
        "4.  **Durability**. Once a transaction is committed, its changes must be permanently stored in the database, even in the event of system failures. This durability is typically achieved through the use of transaction logs and other recovery mechanisms that ensure that committed changes are not lost.\n",
        "\n",
        "By adhering to the ACID properties, transactions help maintain the integrity and reliability of the database, even in the face of failures and concurrent access."
      ],
      "metadata": {
        "id": "6fnsmCgQuCUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transactions in SQLite\n",
        "\n",
        "Now that we understand the concept of transactions and the ACID properties, let's explore how to work with transactions in SQLite.\n",
        "\n",
        "### SQLite's Autocommit Mode\n",
        "\n",
        "By default, SQLite operates in autocommit mode. In this mode, each individual SQL statement is treated as a separate transaction and is automatically committed when it completes successfully. If an error occurs during the execution of a statement, any changes made by that statement are automatically rolled back.\n",
        "\n",
        "While autocommit mode is convenient for simple queries and updates, it may not be suitable for situations where you need to ensure that a group of related statements are executed as a single unit of work.\n",
        "\n",
        "### Explicit Transactions\n",
        "\n",
        "To group multiple SQL statements into a single transaction, you can use the `BEGIN`, `COMMIT`, and `ROLLBACK` commands.\n",
        "\n",
        "1.  `BEGIN`. This command starts a new transaction. Any subsequent SQL statements will be part of this transaction until a `COMMIT` or `ROLLBACK` command is issued.\n",
        "2.  `COMMIT`. This command commits the current transaction, making all the changes made within the transaction permanent. After a `COMMIT`, the database is in a new consistent state.\n",
        "3.  `ROLLBACK`. This command rolls back the current transaction, undoing all the changes made within the transaction. After a `ROLLBACK`, the database is restored to the state it was in before the transaction began.\n",
        "\n",
        "Here's an example of using explicit transactions in SQLite (since the environment we are in automatically auto-commits, we can't actually run the code):"
      ],
      "metadata": {
        "id": "yLCKiXaHuldB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```sql\n",
        "-- Begin a transaction\n",
        "BEGIN;\n",
        "\n",
        "-- Deduct $10,000 from Bruce's savings account\n",
        "UPDATE Accounts SET Balance = Balance - 10000 WHERE AccountID = 2;\n",
        "\n",
        "-- Add $10,000 to Bruce's checking account\n",
        "UPDATE Accounts SET Balance = Balance + 10000 WHERE AccountID = 1;\n",
        "\n",
        "-- Commit the transaction\n",
        "COMMIT;\n",
        "```"
      ],
      "metadata": {
        "id": "ZIewN8GcwAq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we start a transaction with the `BEGIN` command. We then execute two `UPDATE` statements to transfer $10,000 from Bruce's savings account to his checking account. Finally, we use the `COMMIT` command to make the changes permanent.\n",
        "\n",
        "If an error occurs during the transaction, we can use the `ROLLBACK` command to undo all the changes and restore the database to its previous state:"
      ],
      "metadata": {
        "id": "NmyzaXaqwIi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```sql\n",
        "-- Begin a transaction\n",
        "BEGIN;\n",
        "\n",
        "-- Deduct $10,000 from Bruce's savings account\n",
        "UPDATE Accounts SET Balance = Balance - 10000 WHERE AccountID = 2;\n",
        "\n",
        "-- Oops, an error occurs!\n",
        "UPDATE Accounts SET Balance = Balance + 10000 WHERE AccountID = 99999; -- Invalid AccountID\n",
        "\n",
        "-- Rollback the transaction\n",
        "ROLLBACK;\n",
        "```"
      ],
      "metadata": {
        "id": "rHNbbsT6wIs1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, the second `UPDATE` statement fails because the specified `AccountID` doesn't exist. By issuing a `ROLLBACK` command, we undo both the successful and the failed `UPDATE` statements, ensuring that the database remains in a consistent state.\n",
        "\n",
        "### Savepoints\n",
        "\n",
        "In addition to the basic transaction commands, SQLite also supports savepoints. A savepoint allows you to create a named point within a transaction that you can roll back to, without rolling back the entire transaction.\n",
        "\n",
        "To create a savepoint, use the `SAVEPOINT` command followed by a name for the savepoint. To roll back to a savepoint, use the `ROLLBACK TO` command followed by the savepoint name."
      ],
      "metadata": {
        "id": "vo4mh8-CwajI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```sql\n",
        "-- Begin a transaction\n",
        "BEGIN;\n",
        "\n",
        "-- Deduct $10,000 from Bruce's savings account\n",
        "UPDATE Accounts SET Balance = Balance - 10000 WHERE AccountID = 2;\n",
        "\n",
        "-- Create a savepoint\n",
        "SAVEPOINT my_savepoint;\n",
        "\n",
        "-- Attempt to add $10,000 to a non-existent account\n",
        "UPDATE Accounts SET Balance = Balance + 10000 WHERE AccountID = 100;\n",
        "\n",
        "-- Rollback to the savepoint\n",
        "ROLLBACK TO my_savepoint;\n",
        "\n",
        "-- Add $10,000 to Bruce's checking account\n",
        "UPDATE Accounts SET Balance = Balance + 10000 WHERE AccountID = 1;\n",
        "\n",
        "-- Commit the transaction\n",
        "COMMIT;\n",
        "```"
      ],
      "metadata": {
        "id": "GVZpeGK3wb86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we create a savepoint named `my_savepoint` after deducting \\$10,000 from Bruce's savings account. We then attempt to add \\$10,000 to a non-existent account, which fails. By rolling back to `my_savepoint`, we undo only the failed `UPDATE` statement, while keeping the successful deduction from the savings account. Finally, we add $10,000 to Bruce's checking account and commit the transaction.\n",
        "\n",
        "Savepoints provide a way to create more granular control over transactions, allowing you to selectively roll back parts of a transaction without undoing all the changes.\n",
        "\n",
        "By using explicit transactions and savepoints, you can ensure that your database operations are grouped into logical units of work, maintaining the consistency and integrity of your data. As you develop more complex applications, understanding and effectively using transactions will be essential to building robust and reliable systems."
      ],
      "metadata": {
        "id": "SsOxhZgnwnSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concurrent Transactions and Database Locking\n",
        "\n",
        "In real-world scenarios, databases often need to handle multiple transactions simultaneously. This is known as **concurrency**. When multiple transactions access and modify the same data at the same time, it can lead to various issues, such as lost updates, dirty reads, and inconsistent data. To prevent these problems, databases use locking mechanisms to control concurrent access to data.\n",
        "\n",
        "### Concurrency Issues\n",
        "\n",
        "Let's consider a scenario in our Gotham City bank database where two transactions are trying to update the same account balance simultaneously.\n",
        "\n",
        "Transaction 1:\n",
        "\n",
        "```sql\n",
        "-- Read Bruce's checking account balance (Balance = 1000)\n",
        "SELECT Balance FROM Accounts WHERE AccountID = 1;\n",
        "\n",
        "-- Deduct $100 from the balance\n",
        "UPDATE Accounts SET Balance = Balance - 100 WHERE AccountID = 1;\n",
        "\n",
        "-- Commit the transaction\n",
        "COMMIT;\n",
        "```\n",
        "\n",
        "Transaction 2:\n",
        "\n",
        "```sql\n",
        "-- Read Bruce's checking account balance (Balance = 1000)\n",
        "SELECT Balance FROM Accounts WHERE AccountID = 1;\n",
        "\n",
        "-- Deduct $50 from the balance\n",
        "UPDATE Accounts SET Balance = Balance - 50 WHERE AccountID = 1;\n",
        "\n",
        "-- Commit the transaction\n",
        "COMMIT;\n",
        "```\n",
        "\n",
        "If these transactions run concurrently without proper locking, they might both read the initial balance of $1000, and then update the balance based on their individual calculations. As a result, one of the updates may be lost, leading to an inconsistent final balance.\n",
        "\n",
        "### Database Locking\n",
        "\n",
        "To prevent concurrency issues, databases use locking mechanisms. Locks are used to temporarily restrict access to data that is being modified by a transaction. There are two main types of locks:\n",
        "\n",
        "1.  **Shared Locks (Read Locks)**: Shared locks are used when a transaction needs to read data. Multiple transactions can acquire shared locks on the same data simultaneously, as long as no transaction is modifying the data. Shared locks are compatible with other shared locks but incompatible with exclusive locks.\n",
        "2.  **Exclusive Locks (Write Locks)**: Exclusive locks are used when a transaction needs to modify data. Only one transaction can acquire an exclusive lock on a particular piece of data at a time. Exclusive locks are incompatible with both shared locks and other exclusive locks.\n",
        "\n",
        "When a transaction acquires a lock, other transactions that need incompatible locks must wait until the lock is released. This ensures that data is accessed and modified in a controlled and consistent manner.\n",
        "\n",
        "### Locking in SQLite\n",
        "\n",
        "SQLite automatically manages locks for you when you use transactions. When a transaction begins, SQLite acquires the necessary locks on the data that the transaction needs to access or modify. The locks are held until the transaction is committed or rolled back.\n",
        "\n",
        "By default, SQLite uses a locking strategy called \"Serializable\" isolation level. In this level, transactions are fully isolated from each other, and the database ensures that the result of concurrent transactions is the same as if they were executed sequentially.\n",
        "\n",
        "However, SQLite also supports other isolation levels, such as \"Read Committed\" and \"Read Uncommitted,\" which offer different trade-offs between data consistency and concurrency.\n",
        "\n",
        "### Deadlocks\n",
        "\n",
        "In some cases, concurrent transactions can lead to deadlocks. A **deadlock** occurs when two or more transactions are waiting for each other to release locks, resulting in a circular dependency. In such situations, none of the transactions can proceed, and the database must detect and resolve the deadlock by automatically rolling back one or more of the transactions involved.\n",
        "\n",
        "SQLite automatically detects and resolves deadlocks by using a deadlock detection algorithm. When a deadlock is detected, SQLite will rollback one of the transactions to break the circular dependency and allow the other transactions to proceed.\n",
        "\n",
        "Understanding concurrent transactions and database locking is crucial for developing applications that can handle multiple users and ensure data consistency. By using transactions and letting SQLite manage locks for you, you can write more robust and reliable database code.\n",
        "\n",
        "If you go on to take more advanced database classes, you'll cover much more on transactions, locking, and related issues (as these remain active areas of research)."
      ],
      "metadata": {
        "id": "55UCQHG6xhh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Oracle and Cyborg on Database Management\n",
        "Oracle: Hey there, Cyborg! I heard you're diving into the world of database management. It's a fascinating field, and **monitoring** and **reporting** are key to keeping your databases running smoothly. As someone who's been managing Gotham City's crime database for years, I can tell you firsthand how important it is to stay on top of these things.\n",
        "\n",
        "Cyborg: Hi Oracle! Yeah, I'm trying to wrap my head around all these concepts. Can you break it down for me in a way that makes sense?\n",
        "\n",
        "Oracle: Absolutely! When I first started managing Gotham's database, I quickly realized that monitoring is essential. **Monitoring** involves continually observing and tracking various aspects of a database system to ensure it's running smoothly and efficiently. It's like having an early warning system that alerts you whenever there's trouble brewing in your database.\n",
        "\n",
        "Cyborg: That makes sense. So, what kind of things do you monitor in Gotham's database?\n",
        "\n",
        "Oracle: There are several critical areas I keep an eye on. First, I monitor the database's **storage space** and **growth rate**. If the database grows too quickly and consumes too much storage, it can lead to performance issues and even data loss. I set up alerts to notify me when the database size reaches certain thresholds.\n",
        "\n",
        "I also closely monitor the **daily usage patterns** and **throughput** of the database. This helps me understand how the database is being utilized and identify any unusual spikes in activity that could indicate potential issues.\n",
        "\n",
        "Another crucial aspect is monitoring the **system resources**, such as **CPU usage**, **memory consumption**, and **disk I/O**. If any of these resources become overburdened, it can significantly impact the database's performance.\n",
        "\n",
        "Cyborg: Wow, that's a lot to keep track of! How do you stay on top of all this information?\n",
        "\n",
        "Oracle: That's where **reporting** comes into play. **Reporting** involves generating detailed analyses and summaries based on the data collected through monitoring. I've set up automated reports that provide me with daily, weekly, and monthly overviews of the database's performance and health.\n",
        "\n",
        "For example, I receive daily reports on **job completion** and **failure rates**. This helps me ensure that our regular database maintenance tasks, such as backups and data imports, are running smoothly. If a job fails, I'm notified immediately so I can investigate and resolve the issue.\n",
        "\n",
        "I also generate reports on **database connections** and **sessions**, including metrics like **concurrent connections** and **failed connection attempts**. This information helps me optimize the database configuration and ensure that it can handle the expected workload.\n",
        "\n",
        "Cyborg: That's really impressive! Can you give me an example of how monitoring and reporting have helped you prevent or resolve issues in Gotham's database?\n",
        "\n",
        "Oracle: Absolutely! A few months ago, I noticed a sudden spike in **CPU usage** and a slowdown in **query response times**. Through my monitoring and reporting setup, I was able to quickly identify the root cause: a poorly optimized query that was being executed frequently. By working with the development team to refactor the query and add appropriate **indexes**, we were able to significantly improve the database's performance and and reduce the CPU load. It was a great example of how proactive monitoring and reporting can help identify and resolve performance bottlenecks before they cause major issues.\n",
        "\n",
        "Cyborg: That's fantastic! It seems like there's a lot of data being generated through monitoring and reporting. How do you manage and analyze all of this information?\n",
        "\n",
        "Oracle: Great question, Cyborg! This is where **logging** comes into play. Logging involves systematically recording various events, activities, and metrics related to the database system. There are several types of logs that I rely on to keep Gotham's crime database running smoothly.\n",
        "\n",
        "First, there are **system logs**, which capture information about the operating system and hardware on which the database is running. These logs can help identify issues related to system resources, such as CPU, memory, and disk usage.\n",
        "\n",
        "Next, we have **transaction logs**, which record all the changes made to the database as part of each transaction. These logs are crucial for ensuring data integrity and enabling point-in-time recovery in case of a failure. By analyzing transaction logs, I can also identify long-running or resource-intensive transactions that may need optimization.\n",
        "\n",
        "Another important type of log is the **connection log**, which tracks all the incoming connections to the database, including details like client IP addresses, connection times, and disconnections. Connection logs can help me monitor database usage patterns, identify potential security issues, and troubleshoot connectivity problems.\n",
        "\n",
        "Cyborg: Wow, that's a lot of different logs to keep track of! How do you manage and analyze all this log data?\n",
        "\n",
        "Oracle: To manage and analyze log data effectively, I use a combination of tools and techniques. Since Gotham's crime database runs on Ubuntu, I leverage several built-in Linux utilities and open-source tools.\n",
        "\n",
        "For example, I use the `tail` and `grep` commands to monitor log files in real-time and filter out relevant entries based on specific keywords or patterns. This allows me to quickly spot potential issues or anomalies as they occur.\n",
        "\n",
        "I also use tools like `logrotate` to automatically rotate and compress log files on a regular basis, preventing them from consuming too much disk space and making it easier to archive and analyze historical log data.\n",
        "\n",
        "For more advanced log analysis and visualization, I rely on tools like ELK stack (Elasticsearch, Logstash, and Kibana) or Graylog. These tools allow me to centralize log data from multiple sources, perform complex queries and aggregations, and create interactive dashboards and reports.\n",
        "\n",
        "Cyborg: This is incredibly helpful, Oracle! It's clear that monitoring, reporting, and logging are all essential components of effective database management. Thanks for sharing your knowledge and experience with me.\n",
        "\n",
        "Oracle: It's my pleasure, Cyborg! Remember, the key to successful database management is being proactive and data-driven. By leveraging monitoring, reporting, and logging, you can gain deep insights into your database's performance, health, and security, and take timely actions to prevent or resolve issues.\n",
        "\n",
        "As you continue to learn and grow in your database management role, don't hesitate to explore new tools and techniques to streamline your monitoring, reporting, and logging processes. The more efficient and effective you can make these tasks, the more time and energy you'll have to focus on strategic initiatives and driving business value.\n",
        "\n",
        "If you have any more questions or need further guidance, feel free to reach out anytime. I'm always here to help aspiring database heroes like you!"
      ],
      "metadata": {
        "id": "W-0HuEqS2dxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Oracle's Daily Report\n",
        "\n",
        "```\n",
        "# Gotham City Police Department - Daily Database Report\n",
        "\n",
        "Date: 2023-06-12\n",
        "Prepared By: Oracle\n",
        "Database: PostgreSQL 12.8\n",
        "OS: Ubuntu 20.04 LTS\n",
        "\n",
        "## Database Size and Growth\n",
        "- Current database size: 850 GB\n",
        "- Growth in the last 24 hours: 2.5 GB\n",
        "- Estimated time to reach 90% capacity: 45 days\n",
        "\n",
        "## Performance Metrics\n",
        "### CPU Usage\n",
        "- Average CPU usage: 45%\n",
        "- Peak CPU usage: 78% (occurred at 2023-06-11 14:30:00 during the daily crime report generation)\n",
        "\n",
        "### Memory Usage\n",
        "- Average memory usage: 60%\n",
        "- Peak memory usage: 85% (occurred at 2023-06-11 02:00:00 during the nightly batch processing)\n",
        "\n",
        "### Disk I/O\n",
        "- Average read IOPS: 1200\n",
        "- Average write IOPS: 800\n",
        "- Peak read IOPS: 2500 (occurred at 2023-06-11 08:30:00 during the morning data import)\n",
        "- Peak write IOPS: 1800 (occurred at 2023-06-11 23:30:00 during the nightly backup)\n",
        "\n",
        "## Database Connections\n",
        "- Total connections: 8500\n",
        "- Peak concurrent connections: 250\n",
        "- Failed connection attempts: 3 (investigation reveals misconfigured client application)\n",
        "\n",
        "## Job Status\n",
        "- Nightly backup: Completed successfully\n",
        "- Daily crime report generation: Completed successfully\n",
        "- Weekly data archival: Scheduled for 2023-06-13 02:00:00\n",
        "\n",
        "## Query Performance\n",
        "- Slowest query: `SELECT * FROM crime_records WHERE date_reported BETWEEN '2023-01-01' AND '2023-12-31'`\n",
        " - Execution time: 18.5 seconds\n",
        " - Recommendation: Add an index on the `date_reported` column\n",
        "- Most frequently executed query: `SELECT * FROM criminal_records WHERE criminal_id = $1`\n",
        " - Execution count: 12,500\n",
        " - Average execution time: 50 ms\n",
        "\n",
        "## Security and Access Control\n",
        "- Failed login attempts: 2 (from IP address 203.0.113.42, flagged for investigation)\n",
        "- Privilege escalation attempts: 0\n",
        "- User accounts created: 1 (John_Doe, limited access granted)\n",
        "- User accounts deactivated: 0\n",
        "\n",
        "## Replication and Disaster Recovery\n",
        "- Replication lag: 1.2 seconds (within acceptable range)\n",
        "- Last successful failover test: 2023-06-07 03:00:00\n",
        "- Last successful backup restore test: 2023-06-10 04:30:00\n",
        "\n",
        "## Action Items\n",
        "1. Investigate failed connection attempts and take necessary actions\n",
        "2. Implement recommended index on `crime_records.date_reported` column\n",
        "3. Review and optimize most frequently executed query\n",
        "4. Monitor replication lag and take corrective actions if it exceeds 5 seconds\n",
        "5. Schedule next failover and backup restore test for 2023-06-21\n",
        "\n",
        "Note: This report is generated based on data from the last 24 hours and is intended for internal use only. For any questions or concerns, please contact Oracle at oracle@gcpd.gov.\n",
        "```"
      ],
      "metadata": {
        "id": "S2ccseTV3UT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Points Summary\n",
        "\n",
        "-   Indexes are separate data structures that allow the database engine to find and retrieve data more efficiently without scanning the entire table.\n",
        "-   Creating appropriate indexes is crucial for optimizing database performance, but indexes also require additional storage space.\n",
        "-   Transactions ensure data integrity and reliability by treating a sequence of database operations as a single unit of work, adhering to the ACID properties: Atomicity, Consistency, Isolation, and Durability.\n",
        "-   SQLite provides commands like BEGIN, COMMIT, ROLLBACK, and SAVEPOINT to work with transactions and manage changes to the database.\n",
        "-   Concurrent transactions can lead to issues like lost updates and inconsistent data, so databases employ locking mechanisms to control simultaneous access to data.\n",
        "-   Database monitoring involves continuously observing and tracking various aspects of a database system to ensure it's running smoothly and efficiently.\n",
        "-   Reporting generates detailed analyses and summaries based on the data collected through monitoring, helping database administrators make informed decisions.\n",
        "-   Logging systematically records events, activities, and metrics related to the database system, providing valuable information for troubleshooting, performance optimization, and security auditing.\n",
        "-   Database administrators like Oracle rely on a combination of tools, techniques, and best practices to effectively monitor, manage, and optimize databases, ensuring their reliability, performance, and security."
      ],
      "metadata": {
        "id": "Iyap8X9z5TKN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y3ohQ_74zMfO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}